---
title: "Capstone Project"
author: "Eric Kao"
date: "March 26, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(dplyr)
library(plyr)
#preload all the dataframe
math <-read.csv('student-mat.csv')##math class grade
portuguese <-read.csv('student-por.csv')##portugese

join_set=merge(math,portuguese,by=c("school","sex","age","address","famsize","Pstatus", "Medu","Fedu","Mjob","Fjob","reason","nursery","internet", "guardian","guardian","traveltime","studytime","failures", "schoolsup","famsup","activities","higher","romantic", "famrel","freetime","goout","Dalc","Walc","health","absences"))



```

## Student Alcohol Consumption

**Student Alcohol Consumption** dataset is what I decided for my springboard capstone project. You can find the original dataset at [here](https://www.kaggle.com/uciml/student-alcohol-consumption)

Let's take a first look of the dataset.

```{r}

str(join_set)

```



## Including Plots

###Data wrangling

I create grade_mean_portuguese and grade_mean_math to record the average of the student and create another column total_mean to record the average of grade_mean_math and grade_mean_portuguese.

```{r}
library(ggplot2)
join_set<-join_set%>%mutate(grade_mean_math=(G1.x+G2.x+G3.x)/3)%>%mutate(grade_mean_portuguese=(G1.y+G2.y+G3.y)/3)%>%mutate(total_mean = ((grade_mean_math+grade_mean_portuguese)/2) )
```

Next, I change Dalc and Walc into text in order to read the value easier. 
```{r}
join_set$Dalc <- mapvalues(join_set$Dalc, from = 1:5, to = c("Very Low", "Low", "Medium", "High", "Very High"))
join_set$Walc <- mapvalues(join_set$Dalc, from = 1:5, to = c("Very Low", "Low", "Medium", "High", "Very High"))
base1<-ggplot(math,aes(x=Dalc,y= total_mean,col=sex))
```


```{r}
base1+geom_boxplot()
```

```{r}
base1+geom_jitter()+ggtitle("Student distribution dotplot based on Workday alcohol consumption")+labs(x="Workday Alcohol Consumption")
```

```{r}
base1+geom_boxplot()+facet_grid(.~Dalc)+ggtitle("Student boxplot based on Workday alcohol consumption")

```


check grade by sex and Dalc
```{r}
base1_G1<-ggplot(math,aes(x=Dalc,y=G1,col=sex))
base1_G2<-ggplot(math,aes(x=Dalc,y=G2,col=sex))
base1_G3<-ggplot(math,aes(x=Dalc,y=G3,col=sex))
base1_class_sex<-ggplot(math,aes(x=school, col=sex))

```

```{r}
base1_class_sex+geom_bar(aes(fill=sex),stat="count",position = 'fill')+ggtitle("Gender Proportion of each group")

```
The distribution of gender between schools are the same. 


```{r}

#why this is not woring in here
base1_class_sex<-ggplot(math,aes(x=school, col=sex))
base1_class_sex+geom_bar(aes(fill=sex),stat="count",position = "fill")+facet_grid(.~Dalc)+ggtitle("Gender Proportion of each group")

```
Gender proportion of each daily consumption group. Male tends to drink more alcohol than female. 



set up the test set and training set.

```{r}
library(caTools)
set.seed(144)
split = sample.split(math$pass_fail, SplitRatio = 0.65)
train = subset(math,split==TRUE)
test = subset(math,split==FALSE)
```


### Do the linear regression first
```{r}
mathlm = lm(grade_mean ~.-grade_mean-G1-G2-G3-pass_fail,data=train)
summary(mathlm)

portugueselm = lm(grade_mean~.-grade_mean-G1-G2-G3-pass_fail, data=portuguese)
summary(portugueselm)
```

###Logistic Regression

build the regression model

```{r}
mathLOG = glm(train$pass_fail~.-grade_mean-G1-G2-G3, data = train, family = "binomial")
```

Third, use the model to predict the test model

```{r}
predictTest = predict(mathLOG, type = "response", newdata = test)
table(test$pass_fail, predictTest >0.75)

```

##Random Forest
```{r}
library(randomForest)
mathForest = randomForest(pass_fail ~.-grade_mean-G1-G2-G3, data = train, nodesize= 25, ntree=200)
PredictForest = predict(mathForest,newdata = test)
table(test$pass_fail, PredictForest)
```

##Decision tree
```{r}
library(rpart)
library(rpart.plot)
mathTree = rpart(pass_fail~.-grade_mean-G1-G2-G3, data = train, method = "class", control = rpart.control(minbucket = 25))
prp(mathTree)

```


#Use avg grade

##Decision tree
```{r}
library(rpart)
library(rpart.plot)
mathavgTree = rpart(grade_mean~.-pass_fail-G1-G2-G3, data = train, control = rpart.control(minbucket = 25))
prp(mathavgTree)
##dont use method='method in rpart when you're building a regression model'
```


##Regression random forest
```{r}


```


use pass_fail:
logistic 
random forest 
decision tree

use avg grade:
use:
RMAC
decision tree 
regression random forest


